---
title: "Exercise #3"
subtitle: "Fortgeschrittene Statistische Software für NF"
author: "Blasi Martin (12244752)"
date: "`r Sys.Date()`"
output: distill::distill_article
---


## Exercise 1: Initializing git (4 Points)


d)  Name 2 strengths and 2 weaknesses of git. (Don't forget to create a
    commit after this answer, see *1c*)
    
**Strengths**
1. Git is a version control system that allows for great reproducibility of the statistical project
2. Git enables and supports collaboration on the statistical project and tracks all changes to all files

**Weaknesses**
1. Git can be a bit complicated to use
2. Git does not track changes (to e.g. code files) automatically but has to be used explicitly


e)  Knit this exercise sheet. Some new files will automatically be
    generated when knitting the sheet e.g.the HTML page. Ignore these
    files, as we only want to track the source files themselves. You
    can, but don't need to create a `.gitignore` file. Just do not
    commit these files manually.

## Exercise 2: Putting your Repository on GitHub (3 Points)

For this task you will upload your solution to GitHub.

a)  Create a new repository on GitHub in your account named
    `exeRcise-sheet-3`. Make sure you create a **public repository** so
    we are able to see it for grading. Add the link to the repository
    below:

https://github.com/m-blasi/exeRcise-sheet-3.git

b)  Push your code to this new repository by copying and executing the
    snippet on github listed under
    `…or push an existing repository from the command line`.
    
    
c)  Regularly push your latest changes to GitHub again and especially do
    so when you are finished with this sheet.

## Exercise 3: Pixar Films (4 Points)

Download the `pixar_films` and `public_response` datasets from the
GitHub repository and track them in git.

Link:
<https://github.com/rfordatascience/tidytuesday/tree/main/data/2025/2025-03-11>

For small datasets like these adding them to git is not a problem.

```{r}
# Download the pixar_films dataset
download.file(
  url = "https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-11/pixar_films.csv",
  destfile = "pixar_films.csv"
)

# Download the public_response dataset
download.file(
  url = "https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-11/public_response.csv",
  destfile = "public_response.csv"
)
```

a)  Load the `pixar_films` dataset into R. Clean the dataset by removing
    films without a title. Inspect the variable `film_rating`. What are
    the possible values and what do they mean? Create a factor variable
    for the film rating. Why is this appropriate?

```{r}
pixar_films <- read.csv("pixar_films.csv")
```

```{r}
pixar_films <- subset(pixar_films, !is.na(film) & film != "")
```

```{r}
table(pixar_films$film_rating)
```

The films in the dataset take rating values of "G" (General Audience), "PG" (Parental Guidance Suggested) and N/A (not an actual rating, most likely means the rating is missing). The rating is based on the Motion Picture Association (MPA) film rating system and has three further possible values: PG-13, R and NC-17.

```{r}
pixar_films$film_rating <- factor(pixar_films$film_rating)
```

Factor variables are used in R to represent categorical data. Film_rating is a categorical variable, as the ratings are categories and not metric values.


b)  Inspect the film titles manually. Which films form a film series? A
    film series can be identified by a common word in the titles of the
    films, often in conjunction with a number in the title,
    e.g. "Despicable Me" and "Despicable Me 2". Create a dataframe which
    displays a list of the different series with the titles of the films
    and how many films belong to the series. Output the dataframe.
    
```{r}
table(pixar_films$film)
```

Manual Inspection: Five film series can be identified based on the tile similarities: Toy story (1-4), Cars (1-3), Finding Nemo (& Dory), The Incredibles (1 and 2), and Monsters (University and Inc).

```{r}
# Add a new column 'series' manually based on title keywords
pixar_films$series <- NA  # default to NA

pixar_films$series[grepl("Toy Story", pixar_films$film)] <- "Toy Story"
pixar_films$series[grepl("Cars", pixar_films$film)] <- "Cars"
pixar_films$series[grepl("Finding", pixar_films$film)] <- "Finding"
pixar_films$series[grepl("Incredibles", pixar_films$film)] <- "Incredibles"
pixar_films$series[grepl("Monsters", pixar_films$film)] <- "Monsters"

# Filter only rows that are part of a series
series_films <- subset(pixar_films, !is.na(series))
```

```{r}
library(dplyr)

series_summary <- series_films %>%
  group_by(series) %>%
  summarise(
    film_titles = paste(film, collapse = "; "),
    num_films = n()
  ) %>%
  arrange(desc(num_films))

# Output the result
print(series_summary)

```


c)  Load the `public_response` dataframe into R. Convert the
    `cinema_score` variable into a factor while ensuring the factor
    levels are defined in ascending order, from the lowest to the
    highest score. Combine `public_response` with the `pixar_films`
    dataset using an appropriate merge variable.

```{r}
public_response <- read.csv("public_response.csv")
```

```{r}
#Define cinema score levels in ascending order
score_levels <- c("A-", "A", "A+")

#Convert cinema_score to an ordered factor
public_response$cinema_score <- factor(public_response$cinema_score,
                                       levels = score_levels,
                                       ordered = TRUE)
```

```{r}
#Merge datasets by title (keep all pixar_films)
pixar_combined <- merge(pixar_films, public_response, by = "film", all.x = TRUE)
```


d)  Choose one of the variables representing the public response and
    create a bar plot for the films belonging to a series. Here are the
    details of the plot:

    -   The film series are represented on the x-axis.
    -   Your chosen public response variable is displayed on the y-axis.
    -   Each film in the series is represented as a separate bar. Bars
        are grouped by film under their respective series on the x-axis.
        Order the bars within a series according to the release date of
        the films.
    -   A title and axis labels for context.

    What do you notice when comparing the scores of the films in a
    series? Do you see any patterns?

```{r}
library(ggplot2)
library(forcats)

# Filter films that are part of a series and have Rotten Tomatoes score
series_films_plot <- pixar_combined %>%
  filter(!is.na(series), !is.na(rotten_tomatoes)) %>%
  arrange(series, release_date)

# Create an ordered factor for film titles within each series
series_films_plot <- series_films_plot %>%
  group_by(series) %>%
  arrange(release_date, .by_group = TRUE) %>%
  mutate(title_ordered = fct_inorder(film)) %>%
  ungroup()
```

```{r}
# Rotten tomates Plot
ggplot(series_films_plot, aes(x = series, y = rotten_tomatoes, fill = title_ordered)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  labs(
    title = "Rotten Tomatoes Scores by Pixar Film Series",
    x = "Film Series",
    y = "Rotten Tomatoes Score",
    fill = "Film Title"
  ) +
  theme_minimal() +
  theme(plot.margin = margin(t = 20, r = 10, b = 10, l = 10),
  axis.text.x = element_text(angle = 45, hjust = 1),
        legend.text = element_text(size = 8))
```

The visual analysis of the rotten tomatoes score for the given pixar film series shows a striking pattern for all series. The first film of the series is always rated the best. For series with more than two titles (Cars and Toy Story) there is a mixed pattern. Cars was able to bounce back so to speak with a better rating in the third (last) film than in the second, while the toy story films progressively were rated worse (except for the second film being as good as the first).


## Exercise 4: Open Analysis (4 points)

This exercise is a bit more open-ended. You can choose any dataset from
[Our World in Data](https://ourworldindata.org/) and analyze it, while
determining the research question yourself.

a)  Go to <https://github.com/owid/owid-datasets/tree/master/datasets>
    and choose a dataset that interests you. You can have a look at
    <https://ourworldindata.org/> to gather some inspiration.
b)  Download the dataset and track it in git.

```{r}
download.file(
  url = "https://raw.githubusercontent.com/owid/owid-datasets/master/datasets/CO2%20emissions%20by%20city%20-%20C40%20Cities%20(2018)/CO2%20emissions%20by%20city%20-%20C40%20Cities%20(2018).csv",
  destfile = "co2_emissions_cities.csv",
  mode = "wb"
)

co2_cities <- read.csv("co2_emissions_cities.csv")

head(co2_cities)
```


c)  Put the name / title of the dataset and a link to it below.


- Dataset Name: ...
- Link: <https://github.com/owid/owid-datasets/>...


d)  Come up with a (research) question you want to answer with the data
    and briefly explain why you believe this is an interesting question
    within one sentence. It should be a question that can be answered
    with the dataset and using R.
e)  Use R to answer your chosen question. Please limit your analysis to
    the functions and techniques we have covered so far in the course.
    You are **not expected** to use advanced statistical models or
    external packages which haven't been introduced.
f)  Create a meaningful plot / figure with the dataset. Make sure to
    provide a figure caption (via the chunk options / Rmarkdown) and
    correctly label the figure.

## Final Note

Make sure to push all your commits and changes to GitHub before
submitting the exercise sheet.
